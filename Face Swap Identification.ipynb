{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb89e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a94298f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760c4a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77711eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    saved_path=\"saved/random.pt\",\n",
    "    best_saved_path = \"saved/random_best.pt\",\n",
    "    lr=0.001, \n",
    "    EPOCHS = 3,\n",
    "    BATCH_SIZE = 32,\n",
    "    IMAGE_SIZE = 224,\n",
    "    TRAIN_VALID_SPLIT = 0.2,\n",
    "    device=device,\n",
    "    SEED = 42,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    USE_AMP = True,\n",
    "    channels_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8776495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(config['SEED'])\n",
    "# If you or any of the libraries you are using rely on NumPy, you can seed the global NumPy RNG \n",
    "np.random.seed(config['SEED'])\n",
    "# Prevent RNG for CPU and GPU using torch\n",
    "torch.manual_seed(config['SEED'])\n",
    "torch.cuda.manual_seed(config['SEED'])\n",
    "torch.backends.cudnn.benchmarks = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0a06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((config['IMAGE_SIZE'],config['IMAGE_SIZE'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8845924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "my_path = '../Images/My_photos/'\n",
    "\n",
    "data = torchvision.datasets.ImageFolder(root=my_path,transform=data_transforms['test'])\n",
    "print(len(data))\n",
    "train_data,test_data,valid_data = torch.utils.data.dataset.random_split(data,[110,50,47])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82f304d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_data, batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])\n",
    "\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(test_data, batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])\n",
    "valid_dl = torch.utils.data.DataLoader(valid_data, batch_size=32,shuffle=True, num_workers = config['num_workers'],\n",
    "                                          pin_memory = config['pin_memory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d105a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,criterion,optimizer,num_epochs=10):\n",
    "\n",
    "    since = time.time()                                            \n",
    "    batch_ct = 0\n",
    "    example_ct = 0\n",
    "    best_acc = 0.3\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        run_corrects = 0\n",
    "        #Training\n",
    "        model.train()\n",
    "        for x,y in train_dl: #BS=32 ([BS,3,224,224], [BS,4])            \n",
    "            if config['channels_last']:\n",
    "                x = x.to(config['device'], memory_format=torch.channels_last) #CHW --> #HWC\n",
    "            else:\n",
    "                x = x.to(config['device'])\n",
    "            y = y.to(config['device']) #CHW --> #HWC\n",
    "            \n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            #optimizer.zero_grad(set_to_none=True)\n",
    "            ######################################################################\n",
    "            \n",
    "            train_logits = model(x) #Input = [BS,3,224,224] (Image) -- Model --> [BS,4] (Output Scores)\n",
    "            \n",
    "            _, train_preds = torch.max(train_logits, 1)\n",
    "            train_loss = criterion(train_logits,y)\n",
    "            train_loss = criterion(train_logits,y)\n",
    "            run_corrects += torch.sum(train_preds == y.data)\n",
    "            \n",
    "            train_loss.backward() # Backpropagation this is where your W_gradient\n",
    "            loss=train_loss\n",
    "\n",
    "            optimizer.step() # W_new = W_old - LR * W_gradient \n",
    "            example_ct += len(x) \n",
    "            batch_ct += 1\n",
    "            if ((batch_ct + 1) % 400) == 0:\n",
    "                train_log(loss, example_ct, epoch)\n",
    "            ########################################################################\n",
    "        \n",
    "        #validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total = 0\n",
    "        # Disable gradient calculation for validation or inference using torch.no_rad()\n",
    "        with torch.no_grad():\n",
    "            for x,y in valid_dl:\n",
    "                if config['channels_last']:\n",
    "                    x = x.to(config['device'], memory_format=torch.channels_last) #CHW --> #HWC\n",
    "                else:\n",
    "                    x = x.to(config['device'])\n",
    "                y = y.to(config['device'])\n",
    "                valid_logits = model(x)\n",
    "                _, valid_preds = torch.max(valid_logits, 1)\n",
    "                valid_loss = criterion(valid_logits,y)\n",
    "                running_loss += valid_loss.item() * x.size(0)\n",
    "                running_corrects += torch.sum(valid_preds == y.data)\n",
    "                total += y.size(0)\n",
    "            \n",
    "        epoch_loss = running_loss / len(valid_data)\n",
    "        epoch_acc = running_corrects.double() / len(valid_data)\n",
    "        train_acc = run_corrects.double() / len(train_data)\n",
    "        print(\"Train Accuracy\",train_acc.cpu())\n",
    "        print(\"Validation Loss is {}\".format(epoch_loss))\n",
    "        print(\"Validation Accuracy is {}\\n\".format(epoch_acc.cpu()))\n",
    "        if epoch_acc.cpu()>best_acc:\n",
    "            print('One of the best validation accuracy found.\\n')\n",
    "            #torch.save(model.state_dict(), config['best_saved_path'])\n",
    "            best_acc = epoch_acc.cpu()\n",
    "\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    #torch.save(model.state_dict(), config['saved_path'])\n",
    "\n",
    "    \n",
    "def train_log(loss, example_ct, epoch):\n",
    "    loss = float(loss)\n",
    "    print(f\"Loss after \" + str(example_ct).zfill(5) + f\" examples: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "559b82f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/11\n",
      "----------\n",
      "Train Accuracy tensor(0.4545, dtype=torch.float64)\n",
      "Validation Loss is 34.05578783725171\n",
      "Validation Accuracy is 0.40425531914893614\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 1/11\n",
      "----------\n",
      "Train Accuracy tensor(0.4636, dtype=torch.float64)\n",
      "Validation Loss is 19.103316449104472\n",
      "Validation Accuracy is 0.40425531914893614\n",
      "\n",
      "Epoch 2/11\n",
      "----------\n",
      "Train Accuracy tensor(0.4818, dtype=torch.float64)\n",
      "Validation Loss is 9.022491688423969\n",
      "Validation Accuracy is 0.425531914893617\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 3/11\n",
      "----------\n",
      "Train Accuracy tensor(0.4636, dtype=torch.float64)\n",
      "Validation Loss is 2.152670426571623\n",
      "Validation Accuracy is 0.425531914893617\n",
      "\n",
      "Epoch 4/11\n",
      "----------\n",
      "Train Accuracy tensor(0.5364, dtype=torch.float64)\n",
      "Validation Loss is 2.101771549975618\n",
      "Validation Accuracy is 0.5531914893617021\n",
      "\n",
      "One of the best validation accuracy found.\n",
      "\n",
      "Epoch 5/11\n",
      "----------\n",
      "Train Accuracy tensor(0.5273, dtype=torch.float64)\n",
      "Validation Loss is 2.263125627598864\n",
      "Validation Accuracy is 0.5531914893617021\n",
      "\n",
      "Epoch 6/11\n",
      "----------\n",
      "Train Accuracy tensor(0.5545, dtype=torch.float64)\n",
      "Validation Loss is 1.746910475670023\n",
      "Validation Accuracy is 0.5531914893617021\n",
      "\n",
      "Epoch 7/11\n",
      "----------\n",
      "Train Accuracy tensor(0.5636, dtype=torch.float64)\n",
      "Validation Loss is 1.3438447992852394\n",
      "Validation Accuracy is 0.5106382978723404\n",
      "\n",
      "Epoch 8/11\n",
      "----------\n",
      "Train Accuracy tensor(0.5545, dtype=torch.float64)\n",
      "Validation Loss is 1.148242879421153\n",
      "Validation Accuracy is 0.48936170212765956\n",
      "\n",
      "Epoch 9/11\n",
      "----------\n",
      "Train Accuracy tensor(0.6000, dtype=torch.float64)\n",
      "Validation Loss is 1.0665895735963862\n",
      "Validation Accuracy is 0.46808510638297873\n",
      "\n",
      "Epoch 10/11\n",
      "----------\n",
      "Train Accuracy tensor(0.5909, dtype=torch.float64)\n",
      "Validation Loss is 1.03294290380275\n",
      "Validation Accuracy is 0.44680851063829785\n",
      "\n",
      "Epoch 11/11\n",
      "----------\n",
      "Train Accuracy tensor(0.5455, dtype=torch.float64)\n",
      "Validation Loss is 0.9816414067085754\n",
      "Validation Accuracy is 0.425531914893617\n",
      "\n",
      "Training complete in 3m 20s\n"
     ]
    }
   ],
   "source": [
    "mobilenet = models.mobilenet_v3_small(pretrained=True)\n",
    "mobilenet.classifier[3] = nn.Linear(in_features = 1024, out_features = 2, bias = True)\n",
    "model = mobilenet\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = model.to(config['device'])\n",
    "model.load_state_dict(torch.load('saved_models/attack_detection.pt'))\n",
    "optimizer = optim.Adam(model.parameters(),lr=config['lr'])\n",
    "train_model(model,criterion,optimizer,num_epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da57b159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss is 0.7117141199111938\n",
      "Test Accuracy is 0.62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "total = 0\n",
    "\n",
    "for x,y in test_dl:\n",
    "    if config['channels_last']:\n",
    "        x = x.to(config['device'], memory_format=torch.channels_last) #CHW --> #HWC\n",
    "    else:\n",
    "        x = x.to(config['device'])\n",
    "    y = y.to(config['device'])\n",
    "    valid_logits = model(x)\n",
    "    _, valid_preds = torch.max(valid_logits, 1)\n",
    "    valid_loss = criterion(valid_logits,y)\n",
    "    running_loss += valid_loss.item() * x.size(0)\n",
    "    running_corrects += torch.sum(valid_preds == y.data)\n",
    "    total += y.size(0)\n",
    "\n",
    "epoch_loss = running_loss / len(test_data)\n",
    "epoch_acc = running_corrects.double() / len(test_data)\n",
    "print(\"Test Loss is {}\".format(epoch_loss))\n",
    "print(\"Test Accuracy is {}\\n\".format(epoch_acc.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864429b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
