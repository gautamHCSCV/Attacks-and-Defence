# Attacks-and-Defend
Adversarial attacks, their identifications and defenses against them

Results after training (without attacks) on SVHN dataset:</br></br>
### Squeezenet:</br>
Train Accuracy: 0.5633</br>
Validation Loss is 1.0300154278504754</br>
Validation Accuracy is 0.6910725261216963</br></br>

### Shufflenet:</br>
Train Accuracy: 0.7434</br>
Validation Loss is 0.40651249159276304</br>
Validation Accuracy is 0.877343269</br></br></br>


### Mask Based Attacks:</br>
Mask based attacks are a type of brute force attack that uses a combination of masks, rules, and dictionaries to guess passwords. The attacker creates a mask that contains all possible combinations of characters and then uses it to generate passwords. The attacker then tries each generated password against the target system until the correct one is found.</br></br>

### PGD Attacks:</br>
PGD (Projected Gradient Descent) attacks are a type of adversarial attack used to fool deep learning models. They work by adding small, carefully crafted perturbations to an input image in order to cause the model to misclassify it. PGD attacks are considered one of the strongest and most effective types of adversarial attacks, as they are able to fool even state-of-the-art models with high success rates. </br></br></br>


![image](https://user-images.githubusercontent.com/65457437/221339920-a698b014-34ae-439b-9b41-3d1d06d45b1c.png)
</br></br>
Tool used for face-swap: https://github.com/wuhuikai/FaceSwap 
</br></br></br>
AASIST (Audio Anti-Spoofing using Integrated Spectro-Temporal) model results: 
</br></br>
Test Loss is 0.02127577176608164</br>
Test Accuracy is 0.9854014598540146</br>
EER (Equal Error Rate): 0.016034644194756573</br>

